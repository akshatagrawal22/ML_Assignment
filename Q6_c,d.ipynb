{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q6. c,d",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfUkMvTHHAGl"
      },
      "source": [
        "#Akshat Agrawal - IIT2019214"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qrFlAdQcMf-"
      },
      "source": [
        "# Q6.c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb_RdCrkOHKH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from copy import deepcopy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "input_data = pd.read_csv(\"https://raw.githubusercontent.com/akshatagrawal22/ML_Assignment/main/Housing%20Price%20data%20set.csv\")\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSVfOnv7Oyay"
      },
      "source": [
        "#Performing feature scanning on area:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY4PRqTeO5yq"
      },
      "source": [
        "Price_of_house = input_data['price']\n",
        "Area_of_floor = input_data['lotsize']\n",
        "Number_of_bedrooms = input_data['bedrooms']\n",
        "Number_of_bathrooms = input_data['bathrms']\n",
        "\n",
        "Mean_Area_of_floor= np.mean(Area_of_floor)\n",
        "Max_Area_of_floor= max(Area_of_floor)\n",
        "Min_Area_of_floor = min(Area_of_floor)\n",
        "Scaled_area_of_floor = []\n",
        "for i in Area_of_floor:\n",
        "\tScaled_area_of_floor.append((i - Mean_Area_of_floor) / (Max_Area_of_floor- Min_Area_of_floor))\n",
        "\n",
        "Train_features= []\n",
        "for i in range(383):\n",
        "\tTrain_features.append([1, Scaled_area_of_floor[i], Number_of_bedrooms[i], Number_of_bathrooms[i]])\n",
        "Train_price = Price_of_house[:383]\n",
        "Test_price = []\n",
        "Test_features = []\n",
        "for i in range(383, len(Price_of_house)):\n",
        "\tTest_features.append([1, Scaled_area_of_floor[i], Number_of_bedrooms[i], Number_of_bathrooms[i]])\n",
        "\tTest_price.append(Price_of_house[i])\n",
        "m = len(Train_features)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXUSbDlkgkQa"
      },
      "source": [
        "# Function to calculate Slope to find coefficients:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHroLXfggkjQ"
      },
      "source": [
        "def Slope(coefficient, Train_features, Train_price, ind):\n",
        "\terr = 0\n",
        "\tfor i in range(len(Train_features)):\n",
        "\t\titr = 0\n",
        "\t\tfor j in range(len(coefficient)):\n",
        "\t\t\titr = itr + coefficient[j] * Train_features[i][j]\n",
        "\t\terr += (itr - Train_price[i]) * Train_features[i][ind]\n",
        "\treturn err"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-7E2V13gzeh"
      },
      "source": [
        "# Using scaled batch gradient without regularisation:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwo0ahOigy4W"
      },
      "source": [
        "Rate_of_learning = 0.001\n",
        "m = len(Train_features)\n",
        "\n",
        "coefficient = [0, 0, 0, 0]\n",
        "for i in range(5000):\n",
        "\tTemp_coefficient = coefficient.copy()\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t\tTemp_coefficient[j] = Temp_coefficient[j] - ((Rate_of_learning / m) * (Slope(coefficient, Train_features, Train_price, j)))\n",
        "\tcoefficient = Temp_coefficient.copy()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzw2IZkShvQA"
      },
      "source": [
        "#Finding Mean absolute percentage error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNFR1rPTQHan",
        "outputId": "ac9001ca-d973-435a-bd64-f1e6b00d25f5"
      },
      "source": [
        "err = 0\n",
        "for i in range(len(Test_features)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * Test_features[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(Test_features)) * 90\n",
        "print(\"Mean absolute percentage Error is : \" + str(err))\n",
        "print()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute percentage Error is : 17.934312568107753\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeC1AkopQcDu"
      },
      "source": [
        "#Using scaled batch gradient with regularisation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8ldHHD-QcfQ"
      },
      "source": [
        "Rate_of_learning = 0.001\n",
        "Lambda = -49\n",
        "coefficient = [0, 0, 0, 0]\n",
        "\n",
        "for epochs in range(5000):\n",
        "\tTemp_coefficient = coefficient.copy()\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t\tif (j == 0):\n",
        "\t\t\tTemp_coefficient[j] = Temp_coefficient[j] - ((Rate_of_learning / m) * (Slope(coefficient, Train_features, Train_price, j)))\t\n",
        "\t\telse:\n",
        "\t\t\tTemp_coefficient[j] = (1 - Rate_of_learning * Lambda / m) * Temp_coefficient[j] - ((Rate_of_learning / m) * (Slope(coefficient, Train_features, Train_price, j)))\n",
        "\tcoefficient = Temp_coefficient.copy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLkS6WDdlcZk"
      },
      "source": [
        "# Finding Mean absolute percentage Error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiUD2x3Yi6vf",
        "outputId": "d8d1ed1d-416c-4f63-bdae-759d34451e4c"
      },
      "source": [
        "err = 0\n",
        "for i in range(len(Test_features)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * Test_features[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(Test_features)) * 100\n",
        "print(\"Mean absolute percentage Error is : \" + str(err))\n",
        "print()\n",
        "\n",
        "def SlopeStoch(coefficient,Train_features,ActualVal,ind):\n",
        "\titr = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t\titr = itr + coefficient[j]*Train_features[j]\n",
        "\treturn (itr - ActualVal) * Train_features[ind]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute percentage Error is : 19.92701396456417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "kZMkuiD2n-kg",
        "outputId": "3083a78e-3f21-4ebd-973a-5d45222e5c71"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "_= plt.bar([\"With regularisation\",\"Without regularisation\"],height=[18.30641888247704,19.92701396456417])\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SYY1x1EQsuV"
      },
      "source": [
        "#Using Scaled Stochastic gradient without regularisation:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AneUYL11Qs65",
        "outputId": "1155a608-7885-47e3-82df-faefa21fee50"
      },
      "source": [
        "print(\"Using Stochastic gradient without regularisation\")\n",
        "\n",
        "Rate_of_learning = 0.005\n",
        "coefficient = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(coefficient)\n",
        "\n",
        "for iter in range(10):\n",
        "\tfor i in range(len(Train_price)):\n",
        "\t\tTemp_coefficient = coefficient.copy()\n",
        "\t\tfor j in range(4):\n",
        "\t\t\tTemp_coefficient[j] = Temp_coefficient[j] - (Rate_of_learning * (SlopeStoch(coefficient, Train_features[i], Train_price[i], j)))\n",
        "\t\tcoefficient = Temp_coefficient.copy()\n",
        "\n",
        "print(\"Final coefficients are:\")\n",
        "print(coefficient)\n",
        "\n",
        "# Finding Mean absolute percentage Error.\n",
        "err = 0\n",
        "for i in range(len(Test_features)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * Test_features[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(Test_features)) * 100\n",
        "print(\"Mean absolute percentage Error is : \" + str(err))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Stochastic gradient without regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[18648.663069990776, 15073.501985961251, 15766.862790309351, 22357.23427068568]\n",
            "Mean absolute percentage Error is : 32.87903970192347\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTEA9U-GQ7Ha"
      },
      "source": [
        "#Using Scaled Stochastic gradient with regularisation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRG_K03QQ7TX",
        "outputId": "cf03d045-20f7-43d0-8a79-24a60bd75676"
      },
      "source": [
        "print(\"Using Stochastic gradient with regularisation\")\n",
        "\n",
        "Rate_of_learning = 0.005\n",
        "Lambda = 142000\n",
        "coefficient = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(coefficient)\n",
        "\n",
        "for iter in range(10):\n",
        "\tfor i in range(len(Train_price)):\n",
        "\t\tTemp_coefficient = coefficient.copy()\n",
        "\t\tfor j in range(4):\n",
        "\t\t\tif j == 0:\n",
        "\t\t\t\tTemp_coefficient[j] = Temp_coefficient[j] - (Rate_of_learning * (SlopeStoch(coefficient, Train_features[i], Train_price[i], j)))\n",
        "\t\t\telse:\n",
        "\t\t\t\tTemp_coefficient[j] = (1 - Rate_of_learning * Lambda) * Temp_coefficient[j] - (Rate_of_learning * (SlopeStoch(coefficient, Train_features[i], Train_price[i], j)))\n",
        "\t\tcoefficient = Temp_coefficient.copy()\n",
        "\n",
        "print(\"Final coefficients are:\")\n",
        "print(coefficient)\n",
        "\n",
        "# Finding Mean absolute percentage Error.\n",
        "err = 0\n",
        "for i in range(len(Test_features)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * Test_features[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(Test_features)) * 100\n",
        "print(\"Mean absolute percentage Error is : \" + str(err))\n",
        "print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Stochastic gradient with regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[nan, nan, nan, nan]\n",
            "Mean absolute percentage Error is : nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: overflow encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqiWQffYRV_8"
      },
      "source": [
        "#Using Scaled Minibatch gradient without regularisation for batch size = 30:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbug_Eo_RWMj",
        "outputId": "48183539-9230-4d39-cb41-04a475a3eef5"
      },
      "source": [
        "print(\"Using Scaled Minibatch gradient without regularisation for batch size = 30\")\n",
        "\n",
        "Size_of_batch = 30;\n",
        "Rate_of_learning = 0.002\n",
        "coefficient = [0, 0, 0, 0]\n",
        "Number_of_Batches = math.ceil(len(Train_price) / Size_of_batch)\n",
        "equallyDiv = False\n",
        "if (len(Train_price) % Size_of_batch == 0):\n",
        "\tequallyDiv = True;\n",
        "\n",
        "for epoch in range(30):\n",
        "\tfor batch in range(Number_of_Batches):\n",
        "\t\tSummation = [0, 0, 0, 0]\n",
        "\t\tfor j in range(len(coefficient)):\n",
        "\t\t\tfor i in range(Size_of_batch):\n",
        "\t\t\t\tif (batch * Size_of_batch + i == len(Train_features)):\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tValue_predicted = 0.0\n",
        "\t\t\t\tfor wj in range(len(coefficient)):\n",
        "\t\t\t\t\tValue_predicted += coefficient[wj] * Train_features[batch * Size_of_batch + i][wj]\n",
        "\t\t\t\tValue_predicted -= Train_price[batch * Size_of_batch + i]\n",
        "\t\t\t\tValue_predicted *= Train_features[batch * Size_of_batch + i][j]\n",
        "\t\t\t\tSummation[j] += Value_predicted;\n",
        "\n",
        "\t\tif (not equallyDiv and batch == Number_of_Batches - 1):\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tcoefficient[j] -= (Summation[j] / (len(Train_price) % Size_of_batch)) * Rate_of_learning\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tcoefficient[j] -= (Summation[j] / Size_of_batch) * Rate_of_learning\n",
        "print(\"Final coefficients are:\")\n",
        "print(coefficient)\n",
        "\n",
        "# Finding Mean absolute percentage Error.\n",
        "err = 0\n",
        "for i in range(len(Test_features)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * Test_features[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(Test_features)) * 100\n",
        "print(\"Mean absolute percentage Error is : \" + str(err))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Scaled Minibatch gradient without regularisation for batch size = 30\n",
            "Final coefficients are:\n",
            "[5834.079583903288, 1398.7151139126267, 15789.080128016818, 10184.60342876498]\n",
            "Mean absolute percentage Error is : 21.04517419184361\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "bTYugrOqrwjG",
        "outputId": "879068f3-6305-4c33-c8f1-cefe6c9a5b58"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "_= plt.bar([\"With regularisation\",\"Without regularisation\"],height=[19.72984683085249,20.34290336445297])\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D49LY3cuRizB"
      },
      "source": [
        "#Using Scaled Minibatch gradient with regularisation for batch size = 30:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwyO3D_eRi8k",
        "outputId": "36465f8a-7bf1-4228-cd09-eeb8079c9814"
      },
      "source": [
        "print(\"Using Scaled Minibatch gradient with regularisation for batch size = 30\")\n",
        "\n",
        "Size_of_batch = 30;\n",
        "Rate_of_learning = 0.002\n",
        "Lambda = -372\n",
        "coefficient = [0, 0, 0, 0]\n",
        "Number_of_Batches = math.ceil(len(Train_price) / Size_of_batch)\n",
        "equallyDiv = False\n",
        "if (len(Train_price) % Size_of_batch == 0):\n",
        "\tequallyDiv = True;\n",
        "\n",
        "for epoch in range(30):\n",
        "\tfor batch in range(Number_of_Batches):\n",
        "\t\tSummation = [0, 0, 0, 0]\n",
        "\t\tfor j in range(len(coefficient)):\n",
        "\t\t\tfor i in range(Size_of_batch):\n",
        "\t\t\t\tif (batch * Size_of_batch + i == len(Train_features)):\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tValue_predicted = 0.0\n",
        "\t\t\t\tfor wj in range(len(coefficient)):\n",
        "\t\t\t\t\tValue_predicted += coefficient[wj] * Train_features[batch * Size_of_batch + i][wj]\n",
        "\t\t\t\tValue_predicted -= Train_price[batch * Size_of_batch + i]\n",
        "\t\t\t\tValue_predicted *= Train_features[batch * Size_of_batch + i][j]\n",
        "\t\t\t\tSummation[j] += Value_predicted;\n",
        "\n",
        "\t\tif (not equallyDiv and batch == Number_of_Batches - 1):\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tcoefficient[j] -= (Summation[j] / (len(Train_price) % Size_of_batch)) * Rate_of_learning\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcoefficient[j] = (1 - Rate_of_learning * Lambda / m) * coefficient[j] - (Summation[j] / (len(Train_price) % Size_of_batch)) * Rate_of_learning\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tcoefficient[j] -= (Summation[j] / Size_of_batch) * Rate_of_learning\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcoefficient[j] = (1 - Rate_of_learning * Lambda / m) * coefficient[j] - (Summation[j] / Size_of_batch) * Rate_of_learning\n",
        "print(\"Final coefficients are:\")\n",
        "print(coefficient)\n",
        "\n",
        "# Finding Mean absolute percentage Error.\n",
        "err = 0\n",
        "for i in range(len(Test_features)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * Test_features[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(Test_features)) * 100\n",
        "print(\"Mean absolute percentage Error is : \" + str(err))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Scaled Minibatch gradient with regularisation for batch size = 30\n",
            "Final coefficients are:\n",
            "[2681.43806108953, 2059.662947401348, 17584.987500198524, 12538.251896070407]\n",
            "Mean absolute percentage Error is : 20.000670512331244\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZw6_Kq2HNz6"
      },
      "source": [
        "#Q6.d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxCf26jP1HV_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "def calculate_error(matY, y_predicted):\n",
        "    err = 0\n",
        "    for i in range(len(matY)):\n",
        "        err += abs(matY[i] - y_predicted[i]) / matY[i]\n",
        "    err = err / len(matY)\n",
        "    return err * 100\n",
        "\n",
        "def kernel(matX, xi, Tau_parameter):\n",
        "    return np.exp(-np.sum((xi - matX) ** 2, axis = 1) / (2 * Tau_parameter * Tau_parameter))\n",
        "\n",
        "def LocallyWeightedLR(matX, xi, matY, Tau_parameter):\n",
        "\tTransposeMatrixX = np.transpose(matX)\n",
        "\tW = kernel(matX, xi, Tau_parameter)\n",
        "\tMatrixXTransposeW = TransposeMatrixX * W\n",
        "\tMatrixXTransposeWX = np.matmul(MatrixXTransposeW, matX)\n",
        "\tInverseMatrixXTransposeWX = np.linalg.pinv(MatrixXTransposeWX)\n",
        "\tInverseMatrixXTransposeWXMatrixXTransposeW = np.matmul(InverseMatrixXTransposeWX, MatrixXTransposeW)\n",
        "\tInverseMatrixXTransposeWXMatrixXTransposeWY = np.matmul(InverseMatrixXTransposeWXMatrixXTransposeW, matY)\n",
        "\tInverseMatrixXTransposeWXMatrixXTransposeWYTranspose = np.transpose(InverseMatrixXTransposeWXMatrixXTransposeWY)\n",
        "\treturn InverseMatrixXTransposeWXMatrixXTransposeWYTranspose.dot(xi)\n",
        "\n",
        "input_data = pd.read_csv(\"https://raw.githubusercontent.com/akshatagrawal22/ML_Assignment/main/Housing%20Price%20data%20set.csv\", usecols = [\"price\", \"lotsize\", \"bedrooms\", \"bathrms\"])\n",
        "Area_of_floor = input_data['lotsize']\n",
        "Number_of_bedrooms = input_data['bedrooms']\n",
        "Number_of_bathrooms = input_data['bathrms']\n",
        "matY = input_data['price']\n",
        "matY = np.array(matY)\n",
        "matY = matY.reshape(matY.shape[0], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq0cHQra1HWA"
      },
      "source": [
        "#Performing feature scanning on area:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYu6CWeq1HWB",
        "outputId": "adfceb7d-3312-4e67-fb96-8c3d4043224b"
      },
      "source": [
        "Mean_area_of_floor = np.mean(Area_of_floor)\n",
        "Max_area_of_floor = max(Area_of_floor)\n",
        "Min_area_of_floor = min(Area_of_floor)\n",
        "Scaled_area_of_floor = []\n",
        "for i in Area_of_floor:\n",
        "\tScaled_area_of_floor.append((i - Mean_area_of_floor) / (Max_area_of_floor - Min_area_of_floor))\n",
        "\n",
        "matX = []\n",
        "for i in range(len(Area_of_floor)):\n",
        "\tmatX.append([1, Scaled_area_of_floor[i], Number_of_bedrooms[i], Number_of_bathrooms[i]])\n",
        "matX = np.array(matX)\n",
        "\n",
        "Tau_parameter = 0.00005\n",
        "print(\"Using Locally Weighted Linear Regression for Tau = \" + str(Tau_parameter))\n",
        "pred = []\n",
        "for i in range(matX.shape[0]):\n",
        "\ty_predicted = LocallyWeightedLR(matX, matX[i], matY, Tau_parameter)\n",
        "\tpred.append(y_predicted)\n",
        "print(\"Mean absolute percentage err is : \" + str(calculate_error(matY,pred)))\n",
        "print()\n",
        "\n",
        "Price_of_house = input_data['price']\n",
        "\n",
        "#segmenting the features\n",
        "Train_features = []\n",
        "for i in range(383):\n",
        "\tTrain_features.append([1, Scaled_area_of_floor[i], Number_of_bedrooms[i], Number_of_bathrooms[i]])\n",
        "Train_price = Price_of_house[:383]\n",
        "Test_price = []\n",
        "FeaturesTest = []\n",
        "for i in range(383, len(Price_of_house)):\n",
        "\tFeaturesTest.append([1, Scaled_area_of_floor[i], Number_of_bedrooms[i], Number_of_bathrooms[i]])\n",
        "\tTest_price.append(Price_of_house[i])\n",
        "m = len(Train_features)\n",
        "\n",
        "# Function to calculate Slope to find coefficients\n",
        "def Slope(coefficient, Train_features, Train_price, ind):\n",
        "\terr = 0\n",
        "\tfor i in range(len(Train_features)):\n",
        "\t\titr = 0\n",
        "\t\tfor j in range(len(coefficient)):\n",
        "\t\t\titr = itr + coefficient[j] * Train_features[i][j]\n",
        "\t\terr += (itr - Train_price[i]) * Train_features[i][ind]\n",
        "\treturn err"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Locally Weighted Linear Regression for Tau = 5e-05\n",
            "Mean absolute percentage err is : [5.40732082]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwyP3sxe1HWE"
      },
      "source": [
        "#Using scaled batch gradient with regularisation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5IpbTq31HWE",
        "outputId": "cb048a97-809b-429e-a01c-90615172acfe"
      },
      "source": [
        "print(\"Using scaled batch gradient with regularisation\")\n",
        "Rate_of_learning = 0.001\n",
        "Lambda = -49\n",
        "coefficient = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(coefficient)\n",
        "for epochs in range(5000):\n",
        "\tTemp_coefficient = coefficient.copy()\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t\tif (j == 0):\n",
        "\t\t\tTemp_coefficient[j] = Temp_coefficient[j] - ((Rate_of_learning / m) * (Slope(coefficient, Train_features, Train_price, j)))\t\n",
        "\t\telse:\n",
        "\t\t\tTemp_coefficient[j] = (1 - Rate_of_learning * Lambda / m) * Temp_coefficient[j] - ((Rate_of_learning / m) * (Slope(coefficient, Train_features, Train_price, j)))\n",
        "\tcoefficient = Temp_coefficient.copy()\n",
        "print(\"Final coefficients are:\")\n",
        "print(coefficient)\n",
        "\n",
        "# Finding Mean absolute percentage err.\n",
        "err = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * FeaturesTest[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage err is : \" + str(err))\n",
        "print()\n",
        "\n",
        "def SlopeStoch(coefficient,Train_features,ActualVal,ind):\n",
        "\titr = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t\titr = itr + coefficient[j]*Train_features[j]\n",
        "\treturn (itr - ActualVal) * Train_features[ind]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using scaled batch gradient with regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[5037.585668619078, 11147.667574879839, 10378.580439168689, 22647.298983883848]\n",
            "Mean absolute percentage err is : 19.92701396456417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh7n-00U1HWG"
      },
      "source": [
        "#Using Scaled Stochastic gradient with regularisation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCZ26eHY1HWH",
        "outputId": "60c262ee-cb43-4d09-e749-8ca7439b882f"
      },
      "source": [
        "print(\"Using Stochastic gradient with regularisation\")\n",
        "\n",
        "# I tried with different values of tau but found this to be the best.\n",
        "Rate_of_learning = 0.004\n",
        "Lambda = 142000\n",
        "coefficient = [0, 0, 0, 0]\n",
        "print(\"Initial coefficients: \")\n",
        "print(coefficient)\n",
        "\n",
        "for iter in range(10):\n",
        "\tfor i in range(len(Train_price)):\n",
        "\t\tTemp_coefficient = coefficient.copy()\n",
        "\t\tfor j in range(4):\n",
        "\t\t\tif j == 0:\n",
        "\t\t\t\tTemp_coefficient[j] = Temp_coefficient[j] - (Rate_of_learning * (SlopeStoch(coefficient, Train_features[i], Train_price[i], j)))\n",
        "\t\t\telse:\n",
        "\t\t\t\tTemp_coefficient[j] = (1 - Rate_of_learning * Lambda / m) * Temp_coefficient[j] - (Rate_of_learning * (SlopeStoch(coefficient, Train_features[i], Train_price[i], j)))\n",
        "\t\tcoefficient = Temp_coefficient.copy()\n",
        "\n",
        "print(\"Final coefficients are:\")\n",
        "print(coefficient)\n",
        "\n",
        "# Finding Mean absolute percentage err.\n",
        "err = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * FeaturesTest[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage err is : \" + str(err))\n",
        "print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Stochastic gradient with regularisation\n",
            "Initial coefficients: \n",
            "[0, 0, 0, 0]\n",
            "Final coefficients are:\n",
            "[68977.37183533033, 153.6672368058788, 622.1158811423422, 207.34938918615728]\n",
            "Mean absolute percentage err is : 22.392602067246287\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYkcMnreNCg"
      },
      "source": [
        "#Using Scaled Minibatch gradient with regularisation for batch size = 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axiYSfHBeNT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6980a17b-5dda-4bd2-a970-846ebc965d52"
      },
      "source": [
        "print(\"Using Scaled Minibatch gradient with regularisation for batch size = 30\")\n",
        "\n",
        "Size_of_batch = 30;\n",
        "Rate_of_learning = 0.002\n",
        "Lambda = -372\n",
        "coefficient = [0, 0, 0, 0]\n",
        "NoOfBatches = math.ceil(len(Train_price) / Size_of_batch)\n",
        "equallyDiv = False\n",
        "if (len(Train_price) % Size_of_batch == 0):\n",
        "\tequallyDiv = True;\n",
        "\n",
        "for epoch in range(30):\n",
        "\tfor batch in range(NoOfBatches):\n",
        "\t\tSummation = [0, 0, 0, 0]\n",
        "\t\tfor j in range(len(coefficient)):\n",
        "\t\t\tfor i in range(Size_of_batch):\n",
        "\t\t\t\tif (batch * Size_of_batch + i == len(Train_features)):\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tValue_predicted = 0.0\n",
        "\t\t\t\tfor wj in range(len(coefficient)):\n",
        "\t\t\t\t\tValue_predicted += coefficient[wj] * Train_features[batch * Size_of_batch + i][wj]\n",
        "\t\t\t\tValue_predicted -= Train_price[batch * Size_of_batch + i]\n",
        "\t\t\t\tValue_predicted *= Train_features[batch * Size_of_batch + i][j]\n",
        "\t\t\t\tSummation[j] += Value_predicted;\n",
        "\n",
        "\t\tif (not equallyDiv and batch == NoOfBatches - 1):\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tcoefficient[j] -= (Summation[j] / (len(Train_price) % Size_of_batch)) * Rate_of_learning\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcoefficient[j] = (1 - Rate_of_learning * Lambda / m) * coefficient[j] - (Summation[j] / (len(Train_price) % Size_of_batch)) * Rate_of_learning\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(Summation)):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tcoefficient[j] -= (Summation[j] / Size_of_batch) * Rate_of_learning\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcoefficient[j] = (1 - Rate_of_learning * Lambda / m) * coefficient[j] - (Summation[j] / Size_of_batch) * Rate_of_learning\n",
        "print(\"Final coefficients are:\")\n",
        "print(coefficient)\n",
        "\n",
        "# Finding Mean absolute percentage err.\n",
        "err = 0\n",
        "for i in range(len(FeaturesTest)):\n",
        "\tpredicted = 0\n",
        "\tfor j in range(len(coefficient)):\n",
        "\t  \tpredicted = predicted + coefficient[j] * FeaturesTest[i][j]\n",
        "\terr += abs(predicted - Test_price[i]) / Test_price[i]\n",
        "err = (err / len(FeaturesTest)) * 100\n",
        "print(\"Mean absolute percentage err is : \" + str(err))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Scaled Minibatch gradient with regularisation for batch size = 30\n",
            "Final coefficients are:\n",
            "[2681.43806108953, 2059.662947401348, 17584.987500198524, 12538.251896070407]\n",
            "Mean absolute percentage err is : 20.000670512331244\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "IZpxKKuo2IAK",
        "outputId": "5d2993e1-cda7-472d-b7fb-6d135644e6e9"
      },
      "source": [
        "\n",
        "_= plt.bar([\"Scaled batch\",\"Scaled stochastic\",\"Scaled minbatch\"],height=[19.92701396456417,22.391965664113076,19.550681895981263])\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}